{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_play_MNIST case",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherryqcchen/play-tensorflow/blob/master/tensorflow_play_MNIST_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "slrPLYMbD3na",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST数据集， 将每张图的像素（28*28*) 数组展开成向量，长度是28*28=784.图片中的像素强度值介于0-1."
      ]
    },
    {
      "metadata": {
        "id": "ggur3_hyFDim",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST数据集是个形状为[60000,784]的张量。第一个维度是数字index。"
      ]
    },
    {
      "metadata": {
        "id": "6RaXNZMzFE_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST labels 是介于0-9的数字。"
      ]
    },
    {
      "metadata": {
        "id": "OS2vNPHmFfq9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "softmax函数可以给不同的对象分配概率。"
      ]
    },
    {
      "metadata": {
        "id": "Q3NwDBf3Gi7D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "非线性回归的例子："
      ]
    },
    {
      "metadata": {
        "id": "z2D1wmArGaJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdgGwNNNEWhC",
        "colab_type": "code",
        "outputId": "c45b33f3-ae5d-4a0d-d7e6-c8970ffc4019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "#numpy 生产200个随机点\n",
        "x_data= np.linspace(-0.5,0.5,200)[:,np.newaxis]\n",
        "noise = np.random.normal(0,0.02,x_data.shape)#生成随机值与x_data的形状一样\n",
        "y_data= np.square(x_data) + noise\n",
        "\n",
        "#定义placeholder\n",
        "x = tf.placeholder(tf.float32, [None, 1]) \n",
        "y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "#构造神经网络\n",
        "\n",
        "#定義中間層，總共10個神經元\n",
        "Weights_L1 = tf.Variable(tf.random_normal([1, 10])) #定義權值變數，並且初始化為 normal 1*10\n",
        "Biases_L1 = tf.Variable(tf.zeros([1,10])) #定義bias變數，並且初始化為0矩陣\n",
        "Wx_plus_b_L1 = tf.matmul(x, Weights_L1) + Biases_L1  # Weights_L1*x + Biases_L1\n",
        "L1 = tf.nn.tanh(Wx_plus_b_L1) #中間層的輸出 (激活函數為 雙曲正切函數)\n",
        "\n",
        "#定義輸出層，總共1個神經元\n",
        "Weights_L2 = tf.Variable(tf.random_normal([10,1]))\n",
        "Biases_L2 = tf.Variable(tf.zeros([1,1]))\n",
        "Wx_plus_b_L2 = tf.matmul(L1, Weights_L2) + Biases_L2  # Weights_L2*L1 + Biases_L2 (輸出層的輸入，是中間層的輸出L1)\n",
        "prediction = tf.nn.tanh(Wx_plus_b_L2)\n",
        "\n",
        "#二次代價函數 : loss = mean((y - prediction)^2)\n",
        "loss = tf.reduce_mean(tf.square(y_data - prediction))\n",
        "\n",
        "#梯度下降法训练  Gradient desent method  (learning rate = 0.1)\n",
        "gd = tf.train.GradientDescentOptimizer(0.1)\n",
        "#最小化 代價函數 (operator)\n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init) #變數初始化\n",
        "    feed_dict = {x : x_data, y : y_data} #訓練時 要傳入的 feed 的字典\n",
        "    for _ in range(5000):\n",
        "        sess.run(train, feed_dict)   \n",
        "    #獲得預測值\n",
        "    feed_pre_dict = {x : x_data} #觀察預測值時 要傳入的 feed 的字典\n",
        "    pv = sess.run(prediction, feed_pre_dict) #預測值\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.scatter(x_data, y_data)\n",
        "    plt.plot(x_data, pv, 'r-', lw=5)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa8b58506d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xVJwQX92LUDA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST数据集分类-EASY"
      ]
    },
    {
      "metadata": {
        "id": "AUpFhXSMLcRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mha50mJcLgrL",
        "colab_type": "code",
        "outputId": "50e17e51-ec9d-4bab-ac2c-101feeb3cb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "#載入數據集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) #這步有時候會失效,网络问题可能会影响\n",
        "\n",
        "#因為數據集很大，故我們要用stochastic gradient descent，會將資料集分批次，並不會一次將所有資料拿來train (計算量很大)\n",
        "#每一個批次的大小，自己定义\n",
        "batch_size = 100 \n",
        "\n",
        "#計算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size  # // 在python中表示取商\n",
        "\n",
        "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
        "x = tf.placeholder(tf.float32, [None, 784]) # 28 * 28 = 784\n",
        "y = tf.placeholder(tf.float32, [None, 10]) #輸出層，有十個神經元，每個神經元有一個激活值，十個激活值排成一個 1*10的向量"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-330a97ec673b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ursef9yMawY",
        "colab_type": "code",
        "outputId": "79ba2623-ae0b-4231-c2fa-ebb5c25c0052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "#建立一個簡單的神經網路 (只有輸出層，總共10個神經元)\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([1, 10]))\n",
        "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "\n",
        "#二次代價函數 : loss = mean((y - prediction)^2)\n",
        "loss = tf.reduce_mean(tf.square(y - prediction))\n",
        "\n",
        "#Gradient desent method  (learning rate = 0.2)\n",
        "gd = tf.train.GradientDescentOptimizer(0.2)\n",
        "\n",
        "#最小化 代價函數 (operator)\n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#求准确率的方法：如果y標籤最大的值，與prediction標籤最大的值相等，則回傳true\n",
        "#結果存在一個 boolean 的變數中\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
        "\n",
        "#求準確率\n",
        "#轉換格式，boolean 轉成 float，接著在取平均值，得到准确率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(21): #總共疊代21次 (outer loop)，每个周期中加循环\n",
        "        #每一次 outer loop 不一次拿所有的數據集，來做 Gradient desent，這就是 stochastic gradient descent\n",
        "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
        "            #利用 train.next_batch 函數，讀取一個batch的 x, y 存給 batch_xs, batch_ys\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size) #每次获得100张图片，下一次获得101-200张图片...\n",
        "            feed_dict = {x: batch_xs, y: batch_ys}  #拿來feed 的 dictionary\n",
        "            sess.run(train, feed_dict)\n",
        "        #每做完一次 outer loop 計算一次準確率\n",
        "        outer_loop_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
        "        acc = sess.run(accuracy, outer_loop_feed_dict)\n",
        "        print(\"Iter =\" + str(epoch) + \", Testing Accuracy =\" + str(acc)) #打印周期数+准确率"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter =0, Testing Accuracy =0.8319\n",
            "Iter =1, Testing Accuracy =0.8707\n",
            "Iter =2, Testing Accuracy =0.8829\n",
            "Iter =3, Testing Accuracy =0.8879\n",
            "Iter =4, Testing Accuracy =0.8945\n",
            "Iter =5, Testing Accuracy =0.8977\n",
            "Iter =6, Testing Accuracy =0.9\n",
            "Iter =7, Testing Accuracy =0.9013\n",
            "Iter =8, Testing Accuracy =0.9042\n",
            "Iter =9, Testing Accuracy =0.9053\n",
            "Iter =10, Testing Accuracy =0.9062\n",
            "Iter =11, Testing Accuracy =0.9077\n",
            "Iter =12, Testing Accuracy =0.9072\n",
            "Iter =13, Testing Accuracy =0.9093\n",
            "Iter =14, Testing Accuracy =0.9106\n",
            "Iter =15, Testing Accuracy =0.9113\n",
            "Iter =16, Testing Accuracy =0.9112\n",
            "Iter =17, Testing Accuracy =0.9119\n",
            "Iter =18, Testing Accuracy =0.9132\n",
            "Iter =19, Testing Accuracy =0.9135\n",
            "Iter =20, Testing Accuracy =0.9134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iQfKg93aPOnI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "优化，提高准确率到95%：批次大小、增加隐藏层（神经元数量）、初始化方式、代价函数（使用交叉熵？）、优化方法（其他方式？）、训练次数（收敛效果）"
      ]
    },
    {
      "metadata": {
        "id": "rSPQcOqSP4d8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "交叉商loss 函數 (cross entropy loss function): 如果输出神经元是线性的，则二次代价函数是合适的选择；如果输出神经元是S型函数，则交叉熵函数比较适用。"
      ]
    },
    {
      "metadata": {
        "id": "0cmixSMsPIYP",
        "colab_type": "code",
        "outputId": "0921bfaa-ce80-43f0-ad63-a0f6014e3ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "cell_type": "code",
      "source": [
        "#載入數據集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) \n",
        "\n",
        "#每一個批次的大小\n",
        "batch_size = 100 \n",
        "\n",
        "#計算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size \n",
        "\n",
        "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
        "x = tf.placeholder(tf.float32, [None, 784]) \n",
        "y = tf.placeholder(tf.float32, [None, 10]) \n",
        "\n",
        "#建立一個神經網路\n",
        "#隱藏層\n",
        "W1 = tf.Variable(tf.random_normal([784, 15]))\n",
        "b1 = tf.Variable(tf.zeros([1, 15]))\n",
        "L1 = tf.nn.softmax(tf.matmul(x, W1) + b1) #隱藏層的輸出\n",
        "\n",
        "#輸出層\n",
        "W = tf.Variable(tf.zeros([15, 10]))\n",
        "b = tf.Variable(tf.zeros([1, 10]))\n",
        "prediction = tf.nn.softmax(tf.matmul(L1, W) + b)\n",
        "\n",
        "\n",
        "#二次代價函數 : loss = mean((y - prediction)^2)\n",
        "#loss = tf.reduce_mean(tf.square(y - prediction))\n",
        "\n",
        "#交叉熵代价函数：\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction))\n",
        "\n",
        "#Gradient desent method \n",
        "gd = tf.train.AdagradOptimizer(0.31)\n",
        "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
        "\n",
        "#最小化 代價函數 (operator) \n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "#結果存在一個 boolean 的變數中\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
        "\n",
        "#求準確率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(300): \n",
        "       \n",
        "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
        "\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {x: batch_xs, y: batch_ys} \n",
        "            sess.run(train, feed_dict)\n",
        "        if epoch % 20 == 0:\n",
        "            #計算一次準確率\n",
        "            outer_loop_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
        "            acc = sess.run(accuracy, outer_loop_feed_dict)\n",
        "            print(\"Iter=\" + str(epoch) + \", Testing Accuracy=\" + str(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-10-719ebb1d49f9>:29: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Iter=0, Testing Accuracy=0.3469\n",
            "Iter=20, Testing Accuracy=0.6612\n",
            "Iter=40, Testing Accuracy=0.7406\n",
            "Iter=60, Testing Accuracy=0.8244\n",
            "Iter=80, Testing Accuracy=0.8304\n",
            "Iter=100, Testing Accuracy=0.8319\n",
            "Iter=120, Testing Accuracy=0.8323\n",
            "Iter=140, Testing Accuracy=0.8337\n",
            "Iter=160, Testing Accuracy=0.8344\n",
            "Iter=180, Testing Accuracy=0.8354\n",
            "Iter=200, Testing Accuracy=0.8354\n",
            "Iter=220, Testing Accuracy=0.8358\n",
            "Iter=240, Testing Accuracy=0.8359\n",
            "Iter=260, Testing Accuracy=0.8356\n",
            "Iter=280, Testing Accuracy=0.8355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPzsxgE0WODC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dropout：在訓練神經網路的時候，對於不一樣的訓練樣本，遮蔽隱藏層的一些神經元，可以減低 overfitting 的可能\n",
        "以下是一個沒有 Dropout的例子 (keep_prob = 1.0)， Training Accuracy 比 Test Accuracy 準確許多\n",
        "也就是說，這個神經網路已經 Overfitting。\n",
        "使用后Dropout后，准确率收敛速度变慢，避免出现过拟合的情况。"
      ]
    },
    {
      "metadata": {
        "id": "v58ujdk_d5_8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "此Case中，还改变成为AdagradOptimizer"
      ]
    },
    {
      "metadata": {
        "id": "KxI_q5QjWNGK",
        "colab_type": "code",
        "outputId": "0d091a40-7f72-4432-ee3d-906b54c64b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1498
        }
      },
      "cell_type": "code",
      "source": [
        "#載入數據集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) \n",
        "\n",
        "#每一個批次的大小\n",
        "batch_size = 100 \n",
        "\n",
        "#計算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size \n",
        "\n",
        "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
        "x = tf.placeholder(tf.float32, [None, 784]) \n",
        "y = tf.placeholder(tf.float32, [None, 10]) \n",
        "keep_prob = tf.placeholder(tf.float32) #用來 dropout 的機率\n",
        "\n",
        "#建立一個神經網路\n",
        "\n",
        "#增加隐藏层，可能出现过拟合。\n",
        "#隱藏層1\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 2000], stddev=0.1))\n",
        "b1 = tf.Variable(tf.zeros([2000]))\n",
        "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
        "L1_dropout = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "\n",
        "#隱藏層2\n",
        "W2 = tf.Variable(tf.truncated_normal([2000, 2000], stddev=0.1))\n",
        "b2 = tf.Variable(tf.zeros([2000]))\n",
        "L2 = tf.nn.tanh(tf.matmul(L1_dropout, W2) + b2)\n",
        "L2_dropout = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "#隱藏層3\n",
        "W3 = tf.Variable(tf.truncated_normal([2000, 1000], stddev=0.1))\n",
        "b3 = tf.Variable(tf.zeros([1000]))\n",
        "L3 = tf.nn.tanh(tf.matmul(L2_dropout, W3) + b3)\n",
        "L3_dropout = tf.nn.dropout(L3, keep_prob)\n",
        "\n",
        "#輸出層\n",
        "W4 = tf.Variable(tf.truncated_normal([1000, 10], stddev=0.1))\n",
        "b4 = tf.Variable(tf.zeros([10]))\n",
        "prediction = tf.nn.tanh(tf.matmul(L3_dropout, W4) + b4)\n",
        "\n",
        "#代價函數 : loss = mean((y - prediction)^2)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction))\n",
        "\n",
        "#Gradient desent method \n",
        "gd = tf.train.AdagradOptimizer(0.31)\n",
        "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
        "\n",
        "#最小化 代價函數 (operator)\n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "#結果存在一個 boolean 的變數中\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
        "\n",
        "#求準確率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(21): \n",
        "       \n",
        "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
        "\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {x: batch_xs, y: batch_ys, keep_prob: 0.7} \n",
        "            sess.run(train, feed_dict)\n",
        "        #計算一次準確率\n",
        "        train_feed_dict = {x: mnist.train.images, y: mnist.train.labels, keep_prob: 1.0} #train data feed dictionary\n",
        "        train_acc = sess.run(accuracy, train_feed_dict)\n",
        "        test_feed_dict = {x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0} #testing data feed dictionary\n",
        "        test_acc = sess.run(accuracy, test_feed_dict)          \n",
        "        print(\"Iter=\" + str(epoch) + \", Training Accuracy=\" + str(train_acc) + \", Testing Accuracy=\" + str(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Iter=0, Training Accuracy=0.9212546, Testing Accuracy=0.9195\n",
            "Iter=1, Training Accuracy=0.9521818, Testing Accuracy=0.9508\n",
            "Iter=2, Training Accuracy=0.95870906, Testing Accuracy=0.9554\n",
            "Iter=3, Training Accuracy=0.9609454, Testing Accuracy=0.9543\n",
            "Iter=4, Training Accuracy=0.9699636, Testing Accuracy=0.9626\n",
            "Iter=5, Training Accuracy=0.95247275, Testing Accuracy=0.9425\n",
            "Iter=6, Training Accuracy=0.9742727, Testing Accuracy=0.965\n",
            "Iter=7, Training Accuracy=0.9753818, Testing Accuracy=0.9644\n",
            "Iter=8, Training Accuracy=0.9725636, Testing Accuracy=0.9647\n",
            "Iter=9, Training Accuracy=0.9825636, Testing Accuracy=0.9721\n",
            "Iter=10, Training Accuracy=0.9805818, Testing Accuracy=0.9694\n",
            "Iter=11, Training Accuracy=0.98047274, Testing Accuracy=0.9685\n",
            "Iter=12, Training Accuracy=0.9848, Testing Accuracy=0.9721\n",
            "Iter=13, Training Accuracy=0.98496366, Testing Accuracy=0.973\n",
            "Iter=14, Training Accuracy=0.98441815, Testing Accuracy=0.9717\n",
            "Iter=15, Training Accuracy=0.9876364, Testing Accuracy=0.9745\n",
            "Iter=16, Training Accuracy=0.9876909, Testing Accuracy=0.973\n",
            "Iter=17, Training Accuracy=0.9846, Testing Accuracy=0.9678\n",
            "Iter=18, Training Accuracy=0.9889455, Testing Accuracy=0.9751\n",
            "Iter=19, Training Accuracy=0.98954546, Testing Accuracy=0.9747\n",
            "Iter=20, Training Accuracy=0.99076366, Testing Accuracy=0.9755\n",
            "Iter=21, Training Accuracy=0.98858184, Testing Accuracy=0.9745\n",
            "Iter=22, Training Accuracy=0.99054545, Testing Accuracy=0.9767\n",
            "Iter=23, Training Accuracy=0.99274546, Testing Accuracy=0.9776\n",
            "Iter=24, Training Accuracy=0.9937091, Testing Accuracy=0.978\n",
            "Iter=25, Training Accuracy=0.99374545, Testing Accuracy=0.9783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4186f2c7199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;31m#計算一次準確率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtrain_feed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#train data feed dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3aAFUKBJdHwH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Opimizer: 调节成 Adam Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "bgeEjO5edJNA",
        "colab_type": "code",
        "outputId": "a533e023-98cb-49f8-ecd9-9f9bdc73c341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "cell_type": "code",
      "source": [
        "#載入數據集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) \n",
        "\n",
        "#每一個批次的大小\n",
        "batch_size = 100 \n",
        "\n",
        "#計算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size \n",
        "\n",
        "#定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
        "x = tf.placeholder(tf.float32, [None, 784]) \n",
        "y = tf.placeholder(tf.float32, [None, 10]) \n",
        "\n",
        "#建立一個神經網路\n",
        "\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "\n",
        "\n",
        "#二次代價函數 : loss = mean((y - prediction)^2)\n",
        "#loss = tf.reduce_mean(tf.square(y - prediction))\n",
        "\n",
        "#交叉熵代价函数：\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction))\n",
        "\n",
        "#Gradient desent method \n",
        "gd = tf.train.AdamOptimizer(1e-2)\n",
        "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
        "#最小化 代價函數 (operator) \n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "#結果存在一個 boolean 的變數中\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
        "\n",
        "#求準確率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(21): \n",
        "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {x: batch_xs, y: batch_ys} \n",
        "            sess.run(train, feed_dict)\n",
        "        outer_loop_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
        "        acc = sess.run(accuracy, outer_loop_feed_dict)\n",
        "        print(\"Iter=\" + str(epoch) + \", Testing Accuracy=\" + str(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Iter=0, Testing Accuracy=0.9204\n",
            "Iter=1, Testing Accuracy=0.928\n",
            "Iter=2, Testing Accuracy=0.9288\n",
            "Iter=3, Testing Accuracy=0.929\n",
            "Iter=4, Testing Accuracy=0.93\n",
            "Iter=5, Testing Accuracy=0.9318\n",
            "Iter=6, Testing Accuracy=0.929\n",
            "Iter=7, Testing Accuracy=0.9298\n",
            "Iter=8, Testing Accuracy=0.931\n",
            "Iter=9, Testing Accuracy=0.9321\n",
            "Iter=10, Testing Accuracy=0.9307\n",
            "Iter=11, Testing Accuracy=0.9283\n",
            "Iter=12, Testing Accuracy=0.9304\n",
            "Iter=13, Testing Accuracy=0.9307\n",
            "Iter=14, Testing Accuracy=0.9311\n",
            "Iter=15, Testing Accuracy=0.9299\n",
            "Iter=16, Testing Accuracy=0.9292\n",
            "Iter=17, Testing Accuracy=0.9311\n",
            "Iter=18, Testing Accuracy=0.9291\n",
            "Iter=19, Testing Accuracy=0.9308\n",
            "Iter=20, Testing Accuracy=0.9323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rB5Qmg6nhgUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensorboard 使用方法介绍"
      ]
    },
    {
      "metadata": {
        "id": "vhLrMx2-hfoi",
        "colab_type": "code",
        "outputId": "d7fe8986-d122-48f1-82fc-c457bc68f64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "#載入數據集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) \n",
        "\n",
        "#每一個批次的大小\n",
        "batch_size = 100 \n",
        "\n",
        "#計算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size \n",
        "\n",
        "#命名空间\n",
        "with tf.name_scope('input'):\n",
        "    #定義兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
        "    x = tf.placeholder(tf.float32, [None, 784],name='x-input') \n",
        "    y = tf.placeholder(tf.float32, [None, 10],name='y-input') \n",
        "\n",
        "#建立一個神經網路\n",
        "\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "\n",
        "\n",
        "#二次代價函數 : loss = mean((y - prediction)^2)\n",
        "#loss = tf.reduce_mean(tf.square(y - prediction))\n",
        "\n",
        "#交叉熵代价函数：\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction))\n",
        "\n",
        "#Gradient desent method \n",
        "gd = tf.train.AdamOptimizer(1e-2)\n",
        "#gd = tf.train.GradientDescentOptimizer(0.2)\n",
        "#最小化 代價函數 (operator) \n",
        "train = gd.minimize(loss)\n",
        "\n",
        "#初始化變數 operator\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "#結果存在一個 boolean 的變數中\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 回傳一維張量中最大的值，所在的位置\n",
        "\n",
        "#求準確率\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
        "\n",
        "#開始training\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
        "    for epoch in range(1): \n",
        "        for batch in range(n_batch): #每一個 outer loop 疊代 n_batch 個批次\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {x: batch_xs, y: batch_ys} \n",
        "            sess.run(train, feed_dict)\n",
        "        outer_loop_feed_dict = {x: mnist.test.images, y: mnist.test.labels} #testing data feed dictionary\n",
        "        acc = sess.run(accuracy, outer_loop_feed_dict)\n",
        "        print(\"Iter=\" + str(epoch) + \", Testing Accuracy=\" + str(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Iter=0, Testing Accuracy=0.9186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NsNulLXgk0Om",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
        "**在colab使用tensorboard的方法：**"
      ]
    },
    {
      "metadata": {
        "id": "W2-LnsHGk_uf",
        "colab_type": "code",
        "outputId": "908262bd-1eff-448a-d3bb-7484c2d11c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "\n",
        "tbc = TensorBoardColab()\n",
        "summary_writer = tbc.get_writer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://47c63a14.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GPo4QrnAllEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpOgsQQhmSoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}